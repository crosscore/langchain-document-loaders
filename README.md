# langchain-text-splitters

PDF, DOCX, XLSXのそれぞれのテキスト化についての調査結果です。

## 前提
それぞれの拡張子からテキストを抽出することだけを目標とする場合、ライブラリの制約なども比較的自由度が高く簡単です。ただし、テキスト化するだけでは、今回の要件（チャンクに対応する"ファイル名"、"ページ番号"、"シート名"、"行番号"などのセット表示が必要）を満たすことができないことに留意する必要があります。

なぜなら、抽出したテキストだけが存在する場合、テキストがどのロケーション(ページ番号、シート名、行番号など)に存在したかを後から追跡できなくなるためです。

テキスト化の時点で、この情報を追跡できなかった場合、後から特定のチャンクのテキストに関連するロケーション情報を得るには、再度元のファイルを参照する必要があり、これは非効率な上、ほぼ不可能です。

そのため、テキスト化の際には、先に述べたロケーション情報を追跡可能な状態で、それぞれのファイルを読み込む必要があり、それに対応するライブラリを利用することが推奨されます。

## docxのテキスト化
python-docx: 直接的にページ区切りを検出する機能を提供していないためページの特定が不可能

docx2txt:

## xlsxのテキスト化

結論：langchainのライブラリとpandasを試し、langchainライブラリ内でpandasが利用されていることが判りました。最終的にpandasで目的の出力が得られました。

### from langchain_community.document_loaders import UnstructuredExcelLoader を利用する場合

単独では動作せず、以下のライブラリの追加インストールが求められました。
```
unstructured
networkx
psutil
```

インストール後、以下のエラーが発生しました。
```
raise OptionError(f"No such keys(s): {repr(pat)}")
pandas._config.config.OptionError: No such keys(s): 'io.excel.zip.reader'
```
バージョン関連のエラーの可能性があります。また、ライブラリの内部でPandasを利用していることが判明しました。

### pandas(2.2.2)のみを利用する場合
追加ライブラリのインストールが不要です。

ファイル名、シート名、行番号、テキスト、全てが取得できました。
